# AI Style Transfer - PÅ™enos malÃ­Å™skÃ©ho stylu

PokroÄilÃ¡ Streamlit aplikace pro pÅ™enos malÃ­Å™skÃ©ho stylu pomocÃ­ LoRA modelÅ¯ a plnÃ½ch safetensors modelÅ¯ s podporou aÅ¾ 7 GB souborÅ¯.

## ğŸš€ Funkce

- **Podpora velkÃ½ch modelÅ¯**: NahrÃ¡vÃ¡nÃ­ souborÅ¯ aÅ¾ do 10 GB
- **Dva typy modelÅ¯**: LoRA modely (.safetensors) a plnÃ© safetensors modely
- **AutomatickÃ¡ detekce**: RozpoznÃ¡nÃ­ typu modelu na zÃ¡kladÄ› obsahu
- **GPU optimalizace**: AutomatickÃ¡ detekce a vyuÅ¾itÃ­ dostupnÃ©ho hardware
- **Progress tracking**: SledovÃ¡nÃ­ prÅ¯bÄ›hu nahrÃ¡vÃ¡nÃ­ a zpracovÃ¡nÃ­
- **Memory management**: PokroÄilÃ¡ sprÃ¡va pamÄ›ti pro velkÃ© modely
- **Docker podpora**: PÅ™ipraveno pro deployment na RunPod

## ğŸ“‹ PoÅ¾adavky

### LokÃ¡lnÃ­ spuÅ¡tÄ›nÃ­
- Python 3.8+
- CUDA kompatibilnÃ­ GPU (doporuÄeno)
- MinimÃ¡lnÄ› 8 GB RAM (16+ GB doporuÄeno)
- 50+ GB volnÃ©ho mÃ­sta na disku

### RunPod deployment
- GPU instance s minimÃ¡lnÄ› 16 GB VRAM
- Docker support

## ğŸ› ï¸ Instalace

### LokÃ¡lnÃ­ instalace

```bash
# KlonovÃ¡nÃ­ repozitÃ¡Å™e
git clone <repository-url>
cd ai-style-transfer

# Instalace zÃ¡vislostÃ­
pip install -r requirements.txt

# SpuÅ¡tÄ›nÃ­ aplikace
streamlit run app.py
```

### Docker instalace

```bash
# Build Docker image
docker build -t ai-style-transfer .

# SpuÅ¡tÄ›nÃ­ s Docker Compose
docker-compose up
```

## ğŸŒ RunPod Deployment

### PÅ™Ã­prava

1. **Nahrajte Docker image na Docker Hub**:
```bash
docker build -t your-username/ai-style-transfer:latest .
docker push your-username/ai-style-transfer:latest
```

2. **Nastavte RunPod API klÃ­Ä**:
```bash
export RUNPOD_API_KEY="your-api-key"
```

3. **SpusÅ¥te deployment skript**:
```bash
python runpod_deploy.py
```

### ManuÃ¡lnÃ­ deployment na RunPod

1. VytvoÅ™te novÃ½ Pod na RunPod
2. PouÅ¾ijte Docker image: `your-username/ai-style-transfer:latest`
3. Nastavte porty: `8501/http`
4. DoporuÄenÃ© GPU: RTX A5000 nebo lepÅ¡Ã­
5. MinimÃ¡lnÃ­ VRAM: 16 GB
6. Volume: 100 GB pro modely

### Environment Variables

```bash
FORCE_CPU=false                    # Vynutit CPU mÃ­sto GPU
MAX_MEMORY_GB=24                   # MaximÃ¡lnÃ­ pamÄ›Å¥ v GB
ENABLE_ATTENTION_SLICING=true      # PovolĞ¸Ñ‚ÑŒ attention slicing
ENABLE_CPU_OFFLOAD=auto            # CPU offload (true/false/auto)
BASE_MODEL=stabilityai/stable-diffusion-xl-base-1.0  # ZÃ¡kladnÃ­ model
```

## ğŸ“– PouÅ¾itÃ­

### PodporovanÃ© formÃ¡ty modelÅ¯

1. **LoRA modely** (10-500 MB):
   - MalÃ© soubory .safetensors
   - VyÅ¾adujÃ­ zÃ¡kladnÃ­ SDXL model
   - RychlejÅ¡Ã­ naÄÃ­tÃ¡nÃ­

2. **PlnÃ© safetensors modely** (1-7 GB):
   - KompletnÃ­ modely v jednom souboru
   - SamostatnÃ©, nevyÅ¾adujÃ­ zÃ¡kladnÃ­ model
   - PomalejÅ¡Ã­ naÄÃ­tÃ¡nÃ­, ale Äasto lepÅ¡Ã­ kvalita

### Kroky pouÅ¾itÃ­

1. **Nahrajte vstupnÃ­ obrÃ¡zek** (PNG, JPG, JPEG)
2. **Nahrajte model** (.safetensors soubor)
3. **Nastavte parametry**:
   - **Strength** (0.1-1.0): SÃ­la aplikace stylu
   - **Guidance Scale** (1-20): Å˜Ã­zenÃ­ generovÃ¡nÃ­
   - **Inference Steps** (10-50): PoÄet krokÅ¯ generovÃ¡nÃ­
4. **KliknÄ›te na "ğŸ¨ Aplikovat styl"**
5. **StÃ¡hnÄ›te vÃ½sledek**

## âš™ï¸ Konfigurace

### Streamlit konfigurace (.streamlit/config.toml)

```toml
[server]
maxUploadSize = 10240  # 10 GB limit
gatherUsageStats = false

[theme]
base = "dark"
```

### Optimalizace pamÄ›ti

Aplikace automaticky detekuje dostupnou pamÄ›Å¥ a aplikuje optimalizace:

- **Attention Slicing**: SniÅ¾uje VRAM poÅ¾adavky
- **CPU Offload**: PÅ™esouvÃ¡ ÄÃ¡sti modelu na CPU
- **Memory Cleanup**: AutomatickÃ© ÄiÅ¡tÄ›nÃ­ pamÄ›ti
- **Chunked Loading**: PostupnÃ© naÄÃ­tÃ¡nÃ­ velkÃ½ch souborÅ¯

## ğŸ› Å˜eÅ¡enÃ­ problÃ©mÅ¯

### ÄŒastÃ© problÃ©my

1. **"CUDA out of memory"**:
   - SniÅ¾te rozliÅ¡enÃ­ vstupnÃ­ho obrÃ¡zku
   - Nastavte `ENABLE_CPU_OFFLOAD=true`
   - SniÅ¾te `num_inference_steps`

2. **"PEFT backend is required"**:
   - Aplikace automaticky nainstaluje PEFT
   - Restartujte aplikaci po instalaci

3. **PomalÃ© nahrÃ¡vÃ¡nÃ­ velkÃ½ch souborÅ¯**:
   - Zkontrolujte internetovÃ© pÅ™ipojenÃ­
   - Progress bar zobrazuje prÅ¯bÄ›h

### Logy a debugging

```bash
# SpuÅ¡tÄ›nÃ­ s debug mÃ³dem
streamlit run app.py --logger.level=debug

# SledovÃ¡nÃ­ GPU pamÄ›ti
nvidia-smi -l 1
```

## ğŸ“Š VÃ½kon

### DoporuÄenÃ© konfigurace

| GPU | VRAM | DoporuÄenÃ© nastavenÃ­ |
|-----|------|----------------------|
| RTX 3060 | 12 GB | CPU Offload: true, Attention Slicing: true |
| RTX 3080 | 10 GB | CPU Offload: auto, Attention Slicing: true |
| RTX 4090 | 24 GB | CPU Offload: false, Attention Slicing: false |
| A100 | 40 GB | VÅ¡echny optimalizace vypnutÃ© |

### ÄŒasy generovÃ¡nÃ­ (pÅ™ibliÅ¾nÃ©)

- **LoRA model**: 30-60 sekund
- **PlnÃ½ safetensors**: 60-120 sekund
- **CPU pouze**: 5-15 minut